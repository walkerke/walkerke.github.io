{
  "hash": "e25c77c96c4a93b2e221b311fdd0468c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Building an AI-powered location explorer with Shiny and Claude\"\nauthor: \"Kyle Walker\"\ndate: \"2025-04-03\"\ncategories: [r, gis, shiny, AI]\nimage: \"example.gif\"\nfilters:\n- lightbox\nlightbox: auto\neditor:\n   markdown:\n      wrap: 72\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n```\n:::\n\n\n\nLarge language models (LLMs), and the tech ecosystem around them, have\nopened up exciting new possibilities for interactive apps that combine\nspatial data and AI-powered insights. In this post, I'll walk through a\nworkflow for creating a Shiny app that allows users to search for\nlocations and receive AI-generated information about them using\nAnthropic's Claude model.\n\nYou'll learn how to integrate brand-new tools like the **ellmer** and\n**shinychat** packages into your Shiny apps, giving the user a similar\nexperience to using a familiar LLM app like Claude or ChatGPT.\n\n![](example.gif)\n\n## Application overview and tech stack\n\nWe'll be using the following R packages to build the application:\n\n-   [shiny](https://shiny.posit.co/) for the web application framework;\n-   [mapgl](https://walker-data.com/mapgl/) for the interactive mapping\n    interface;\n-   [ellmer](https://ellmer.tidyverse.org/) for LLM integration;\n-   [shinychat](https://posit-dev.github.io/shinychat/) for chat UI and\n    server components in Shiny;\n-   [bslib](https://rstudio.github.io/bslib/) to help us build a modern\n    Shiny UI with minimal code.\n\nThe workflow combines these tools to create an application where users\ncan:\n\n1.  Search for a location using a built-in geocoder\n2.  Interact with the map\n3.  Automatically receive AI-generated information about the location\n    they've selected\n\n## Connecting to Claude\n\nThe heart of our application is the LLM that will provide information\nabout locations. We'll use Anthropic's Claude model, which has shown\nimpressive capabilities in understanding geographical and cultural\ncontext. The **ellmer** package provides a straightforward interface to\nconnect with Claude:\n\n``` r\n# Initialize LLM chat object using Claude\nllm_chat <- chat_claude(\n model = \"claude-3-7-sonnet-latest\",\n system_prompt = \"You are a knowledgeable assistant that provides concise,\n interesting facts about geographical locations. When given location data,\n provide a brief overview of the location, including historical significance,\n cultural importance, or interesting facts if applicable. Keep your response\n conversational and engaging.\"\n)\n```\n\nThe system prompt is crucial here - it defines the role and style of\nresponses that Claude will provide. I've crafted it to generate concise,\nengaging information about locations without being overly verbose.\n\n## Building the Shiny UI\n\nFor the user interface, we'll use **bslib**'s modern layout components,\nwhich provide a clean, responsive design with minimal code:\n\n``` r\nui <- page_sidebar(\n  padding = 0,\n  sidebar = sidebar(\n    title = \"AI-powered Location Explorer\",\n    p(\"Search for a location using the map's search box, and I'll tell you\n      interesting facts about it!\"),\n    hr(),\n    output_markdown_stream(\"location_info\")\n  ),\n\n  mapboxglOutput(\"map\", height = \"100%\")\n)\n```\n\nThe UI is straightforward - a sidebar that will display location\ninformation and a main content area with our interactive map. The\n`output_markdown_stream()` function is a key component that allows us to\nstream the AI-generated content to the user as it's being generated,\nrather than waiting for the complete response.\n\nSetting up the interactive map\n\nFor the mapping component, I'll use my **mapgl** package, which provides\nan interface to Mapbox GL JS. One particularly nice feature is the\nbuilt-in geocoder, which allows users to search for locations:\n\n``` r\n# Initialize map with Mapbox geocoder\noutput$map <- renderMapboxgl({\n mapboxgl(\n   center = c(0, 0),\n   zoom = 1\n ) |>\n   add_geocoder_control(\n     position = \"top-right\",\n     placeholder = \"Search for a location...\",\n     collapsed = FALSE\n   )\n})\n```\n\nThe geocoder control appears as a search box on the map, allowing users\nto search for places by name. When a user selects a location from the\nsearch results, the map will automatically pan and zoom to that\nlocation.\n\n## Connecting the geocoder to Claude\n\nNow comes the exciting part - connecting the geocoder to Claude to\ngenerate information about the selected location. We'll use the\n`observeEvent()` function to react when a user selects a location from\nthe geocoder:\n\n``` r\n# React to geocoding results\nobserveEvent(input$map_geocoder, {\n geocode_result <- input$map_geocoder$result\n\n if (!is.null(geocode_result)) {\n   # Create prompt for the LLM\n   prompt <- paste(\n     \"Please tell me about this location:\",\n     toJSON(geocode_result),\n     \"\\nProvide a brief overview focusing on why this place is significant or teresting.\"\n   )\n\n   # Use ellmer's built-in streaming async functionality\n   stream <- llm_chat$stream_async(prompt)\n\n   # Stream the response to the markdown output\n   markdown_stream(\n     id = \"location_info\",\n     content_stream = stream,\n     operation = \"replace\"\n   )\n }\n})\n```\n\nThis code:\n\n1.  Detects when a user selects a location from the geocoder\n2.  Formats a prompt for Claude, including the JSON data about the\n    location returned by the geocoder;\n3.  Initiates an asynchronous stream of the AI response\n4.  Updates the sidebar with the streaming content\n\nThe streaming approach we've set up works quite well as it gives the\nuser a similar feel to chatting with an LLM app.\n\n## Putting it all together\n\nHere's the complete code for our AI location explorer application; only\n69 lines of R! To get this to work, you will need to get both a Mapbox\naccess token and an Anthropic API key and set them as environment\nvariables.\n\n``` r\nlibrary(shiny)\nlibrary(mapgl) # Assumes the env variable MAPBOX_PUBLIC_TOKEN is set\nlibrary(ellmer) # Assumes the env variable ANTHROPIC_API_KEY is set\nlibrary(shinychat)\nlibrary(jsonlite)\nlibrary(bslib)\n\n# Initialize LLM chat object using Claude\nllm_chat <- chat_claude(\n  model = \"claude-3-7-sonnet-latest\",\n  system_prompt = \"You are a knowledgeable assistant that provides concise, interesting facts about geographical locations. When given location data, provide a brief overview of the location, including historical significance, cultural importance, or interesting facts if applicable. Keep your response conversational and engaging.\"\n)\n\n# UI with simple bslib page_sidebar\nui <- page_sidebar(\n  padding = 0,\n  sidebar = sidebar(\n    title = \"AI-powered Location Explorer\",\n    p(\"Search for a location with the map's geocoder, and I'll tell you interesting facts about it!\"),\n    hr(),\n    output_markdown_stream(\"location_info\")\n  ),\n  \n  # Main content area with the map\n  mapboxglOutput(\"map\", height = \"100%\"),\n)\n\n# Server\nserver <- function(input, output, session) {\n  # Initialize map with Mapbox geocoder\n  output$map <- renderMapboxgl({\n    mapboxgl(\n      center = c(0, 0),\n      zoom = 1\n    ) |>\n      add_geocoder_control(\n        position = \"top-right\",\n        placeholder = \"Search for a location...\",\n        collapsed = FALSE\n      )\n  })\n  \n  # React to geocoding results\n  observeEvent(input$map_geocoder, {\n    geocode_result <- input$map_geocoder$result\n    \n    if (!is.null(geocode_result)) {\n      # Create prompt for the LLM\n      prompt <- paste(\n        \"Please tell me about this location:\",\n        toJSON(geocode_result),\n        \"\\nProvide a brief overview focusing on why this place is significant or interesting.\"\n      )\n      \n      # Use ellmer's built-in streaming async functionality\n      stream <- llm_chat$stream_async(prompt)\n      \n      # Stream the response to the markdown output\n      markdown_stream(\n        id = \"location_info\",\n        content_stream = stream,\n        operation = \"replace\"\n      )\n    }\n  })\n}\n\n# Run the app\nshinyApp(ui, server)\n```\n\n## Example usage and results\n\nLet's say a user searches for \"Fort Worth, Texas\" (where I live). The\ngeocoder will find the location, place a marker there, and fly to the\nlocation. Claude then returns a brief summary of that location based on\nthe information accessible to it. Here's an example response:\n\n> Fort Worth, Texas is known as \"Where the West Begins\" and offers a\n> fascinating blend of cowboy heritage and modern culture. Originally\n> established as an army outpost in 1849, it evolved into a major cattle\n> industry hub along the legendary Chisholm Trail. Today, the city\n> preserves its Western roots in the Stockyards National Historic\n> District while embracing arts and culture through world-class museums\n> like the Kimbell Art Museum and the Modern Art Museum. Fort Worth\n> balances its authentic Western spirit with cosmopolitan amenities,\n> hosting the famous twice-daily cattle drive and maintaining a distinct\n> identity separate from its neighbor Dallas, with whom it forms the\n> core of the DFW metroplex, one of America's largest urban areas.\n\n![](images/clipboard-2420629953.png)\n\nTyping in an address will typically get you more specific information\nabout that location, depending on what Claude knows about it.\n\n## Technical and practical considerations\n\nWhile this application is designed as a proof-of-concept, there are\nseveral enhancements you'll want to consider before deploying something\nlike this in a production environment. While the inputs to the LLM are\nrelatively structured as they *must* correspond to a geocoded result,\nyou may want to add error handling for cases where the LLM doesn't know\nhow to interpret the input. I also haven't put in safeguards to control\nthe output I get back from the LLM beyond a relatively simple system\nprompt. A more tailored approach might use few-shot prompting to feed\nsome examples to the LLM to guide its output. You'll also need to handle\nyour Mapbox and Anthropic API keys securely; I quite like how Posit\nConnect Cloud does this for deployed Shiny apps.\n\nMore broadly, we're also being very trustworthy of Claude here to return\naccurate information. What we're getting is similar to a query about a\nplace you might make in the Claude app. If using this in a production\nenvironment, you may want to consider implementing validation checks or\nuse RAG to help control the information returned.\n\nIf you're interested in learning more about integrating AI with your\nmaps and geospatial applications, or if you'd like a custom workshop on\nthese topics for your organization, please don't hesitate to reach out\nto [kyle\\@walker-data.com](mailto:kyle@walker-data.com){.email}!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}